{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7f00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Allow this notebook to import local libraries \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be5b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_modelling.preprocessor_all import load_data\n",
    "from topic_modelling.pipelines import basic_pipeline, spacy_pipeline\n",
    "from topic_modelling.preprocessor_all import load_data\n",
    "from topic_modelling.models import BasicModel, HierarchicalModel, EnsembleModel, NMFModel\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7841ac",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load and preprocess data](#1)\n",
    "* [2. Date-preprocessing](#2)\n",
    "    * [2.1 LDA Basic Mode](#2.1)\n",
    "        * [2.1.1 Hyper-parameter Tuning](#2.1.1)\n",
    "        * [2.1.2 Find best number of topics](#2.1.2)\n",
    "        * [2.1.3 Grid Search](#2.1.3)\n",
    "    * [2.2 NMF](#2.2)\n",
    "    * [2.3 Ensemble](#2.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c6a28",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess data <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f27799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:load_data took: 0.50 seconds\n",
      "Func:reset_index took: 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98a5c5f6d34825975b202239ee09f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:demoji_preprocessor took: 19.73 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9867410010be457aa956b134295538de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:tweet_preprocessor took: 1.19 seconds\n",
      ":: Spacy preprocessor -> cleaning, this might take 1-2 minutes....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de721cc39c724c54b7a0ebff998c9d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:spacy_preprocessor took: 56.63 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e082eefe5d4cf6b17721846d2fd695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:predefined_denoiser took: 0.09 seconds\n",
      "Func:drop_empty took: 0.02 seconds\n",
      "Func:reset_index took: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f721d8e37c4574aedf752e548f3787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:tokenizer_transformer took: 0.30 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28de917e988e4aaf8793bad8d7521c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/42360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func:ngrammer_2_3_pre_trained took: 0.30 seconds\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "df = spacy_pipeline.apply(df, column='cleanBody')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf04be2",
   "metadata": {},
   "source": [
    "# 2. Model Selection<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf12c",
   "metadata": {},
   "source": [
    "## 2.1 LDA Basic Model<a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = BasicModel()\n",
    "basic_model.fit(df,'cleanBody')\n",
    "basic_model.train(num_topics=6, \n",
    "                  passes=1,\n",
    "                  chunksize=100,\n",
    "                  eval_every=10,\n",
    "                  alpha = 0.9,\n",
    "                  decay=0.3,\n",
    "                  tfidf = False\n",
    "                 )\n",
    "\n",
    "print(basic_model.get_coherance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1a8adb",
   "metadata": {},
   "source": [
    "## 2.1 LDA Tfidf Model<a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c30ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Size of id2word: 25387\n",
      "Func:createid2word_dictionary took: 0.25 seconds\n",
      "Func:filter_extremes took: 0.02 seconds\n",
      "Func:create_bow_coprpus took: 0.23 seconds\n",
      "Func:create_tfidf_corpus took: 0.04 seconds\n",
      "----> Training BasicModel <----\n",
      "Func:train took: 4.17 seconds\n",
      "\n",
      "Coherence Score:  0.5134443317718471\n",
      "Func:get_coherance took: 2.71 seconds\n",
      "0.5134443317718471\n"
     ]
    }
   ],
   "source": [
    "lda_tfidf_model = BasicModel()\n",
    "lda_tfidf_model.fit(df,'cleanBody')\n",
    "lda_tfidf_model.train(num_topics=6, \n",
    "                  passes=1,\n",
    "                  chunksize=500,\n",
    "                  eval_every=10,\n",
    "                  alpha = 'symmetric',\n",
    "                  decay=0.1,\n",
    "                  tfidf = True\n",
    "                 )\n",
    "\n",
    "print(lda_tfidf_model.get_coherance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42039bf",
   "metadata": {},
   "source": [
    "### 2.1.1 Hyper-parameter Tuning<a class=\"anchor\" id=\"2.1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a4371",
   "metadata": {},
   "source": [
    "### 2.1.2 Find best number of topics<a class=\"anchor\" id=\"2.1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = basic_model.compute_coherence_values(start=6, limit=18, step=1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,c in (zip(model_list, coherence_values)):\n",
    "    print(f\"Topics:{m.num_topics},Coherence score:{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36227ac",
   "metadata": {},
   "source": [
    "### 2.1.3 Grid Search<a class=\"anchor\" id=\"2.1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def grid_search(df:pd.DataFrame,  k_start=5, k_end=12, k_step=1,\n",
    "                alpha_start=0.2, alpha_end=1, alpha_step=0.2,\n",
    "                decay_start=0.1, decay_end=0.5, decay_step=0.1\n",
    "               )-> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Create several models using different ranges for Alpha, Betta and Number of topics\n",
    "    Part of the code was retrieved from : https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "    \"\"\"\n",
    "\n",
    "    grid = {}\n",
    "\n",
    "    # Topics\n",
    "    topics_range = range(k_start, k_end, k_step)\n",
    "    # ALPHA\n",
    "    alpha_range = list(np.arange(alpha_start, alpha_end, alpha_step)) \n",
    "    alpha_range.append('symmetric')\n",
    "    alpha_range.append('asymmetric')\n",
    "    # Decay\n",
    "    decay_range = list(np.arange(decay_start, decay_end, decay_step))\n",
    "    \n",
    "    chunksize_range = [100,300,500]\n",
    "    passes_range = [1]\n",
    "    model_results = {\n",
    "                     'Topics': [],\n",
    "                     'Alpha': [],\n",
    "                     'Decay': [],\n",
    "                     'Chunksize': [],\n",
    "                     'Passes': [],\n",
    "                     'Coherence': []\n",
    "                    }\n",
    "\n",
    "    total_combinations = len(topics_range)*len(alpha_range)*len(decay_range)*len(chunksize_range)*len(passes_range)\n",
    "    print(f\"Total Models to grid search: {total_combinations}\")\n",
    "\n",
    "    with tqdm.tqdm(total=total_combinations)as pbar:\n",
    "\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha_range:\n",
    "                # iterare through decay values\n",
    "                for d in decay_range:\n",
    "                    # iterare through chunk sizes\n",
    "                    for c in chunksize_range:\n",
    "                        # iterare through chunk sizes\n",
    "                        for p in passes_range:\n",
    "                            # get the coherence score for the given parameters\n",
    "                            cv = basic_model.compute_coherence_for_topics_a_d(k=k, a=a, d=d, c=c, p=p, tfidf=True)\n",
    "                            # Save the model results\n",
    "                            model_results['Topics'].append(k)\n",
    "                            model_results['Alpha'].append(a)\n",
    "                            model_results['Decay'].append(d)\n",
    "                            model_results['Chunksize'].append(c)\n",
    "                            model_results['Passes'].append(p)\n",
    "                            model_results['Coherence'].append(cv)\n",
    "                            pbar.update(1)\n",
    "\n",
    "        grid_search_results = pd.DataFrame(model_results).to_csv('gridSearch_results2.csv', index=False)\n",
    "        pbar.close()\n",
    "    \n",
    "    return grid_search_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e56c8",
   "metadata": {},
   "source": [
    "### Run grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ebccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = grid_search(\n",
    "    df.cleanBody.to_list(),\n",
    "    k_start=4, k_end=8, k_step=1,\n",
    "    alpha_start=0.5, alpha_end=1, alpha_step=0.1,\n",
    "    decay_start=0.1, decay_end=0.3, decay_step=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c0387",
   "metadata": {},
   "source": [
    "### Load Previous Grid Search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd6603",
   "metadata": {},
   "source": [
    "### Bow LDA gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.read_csv('gridSearch_results.csv')\n",
    "grid_search_results.sort_values(by='Coherence', ascending= False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af4198",
   "metadata": {},
   "source": [
    "### TFIDF LDA gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78894290",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.read_csv('gridSearch_results2.csv')\n",
    "grid_search_results.sort_values(by='Coherence', ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec559d1f",
   "metadata": {},
   "source": [
    "### 2.1.4 Hierarchical Dirichlet Process<a class=\"anchor\" id=\"2.1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpModel = HierarchicalModel()\n",
    "hdpModel.fit(df,'cleanBody')\n",
    "hdpModel.train()\n",
    "\n",
    "print(hdpModel.get_coherance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b618a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdpModel.model.show_topics(num_topics=8, formatted=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def topic_prob_extractor(gensim_hdp):\n",
    "    shown_topics = gensim_hdp.show_topics(num_topics=30, num_words=10, formatted=False)\n",
    "    topics_nos = [x[0] for x in shown_topics ]\n",
    "    weights = [ sum([item[1] for item in shown_topics[topicN][1]]) for topicN in topics_nos ]\n",
    "\n",
    "    return pd.DataFrame({'topic_id' : topics_nos, 'weight' : weights})\n",
    "\n",
    "topic_prob_extractor(hdpModel.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a06f6",
   "metadata": {},
   "source": [
    "## 2.2 NMF<a class=\"anchor\" id=\"2.2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6eb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMFModel()\n",
    "nmf_model.fit(df, 'cleanBody')\n",
    "nmf_model.train(num_topics=10)\n",
    "\n",
    "print(nmf_model.get_topics())\n",
    "print(nmf_model.get_coherance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1faf6",
   "metadata": {},
   "source": [
    "## 2.3 Ensemble<a class=\"anchor\" id=\"2.3\"></a>\n",
    "https://radimrehurek.com/gensim/models/ensemblelda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75587ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel()\n",
    "ensemble_model.fit(df, 'cleanBody')\n",
    "ensemble_model.train(num_topics=10, num_models=10)\n",
    "\n",
    "print(ensemble_model.get_topics())\n",
    "print(ensemble_model.get_coherance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a42016",
   "metadata": {},
   "source": [
    "# 3. Topic Analysis<a class=\"anchor\" id=\"3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119dce39",
   "metadata": {},
   "source": [
    "## 3.1 LDA Model<a class=\"anchor\" id=\"3.1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = gensimvis.prepare(topic_model=basic_model.model, corpus=basic_model.corpus, dictionary=basic_model.id2word)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ac55a",
   "metadata": {},
   "source": [
    "## 3.2 LDA Tfidf Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74e61f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_tfidf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vis \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(topic_model\u001b[38;5;241m=\u001b[39m\u001b[43mlda_tfidf_model\u001b[49m\u001b[38;5;241m.\u001b[39mmodel, corpus\u001b[38;5;241m=\u001b[39mlda_tfidf_model\u001b[38;5;241m.\u001b[39mcorpus_tfidf, dictionary\u001b[38;5;241m=\u001b[39mbasic_model\u001b[38;5;241m.\u001b[39mid2word)\n\u001b[1;32m      2\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[1;32m      3\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mdisplay(vis)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_tfidf_model' is not defined"
     ]
    }
   ],
   "source": [
    "vis = gensimvis.prepare(topic_model=lda_tfidf_model.model, corpus=lda_tfidf_model.corpus_tfidf, dictionary=basic_model.id2word)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef8315",
   "metadata": {},
   "source": [
    "# 4. Model Selection and Analysis\n",
    "Based on Grid Search we identify that 6,7,8 total topics yield high coherance. However we can see that when have 8 topics, some clusters are overlapping. So I chose 6 so we can have distinc clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1735fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tfidf_model.freeze_model(\"lda_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f43ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.16666667), (1, 0.16666667), (2, 0.16666667), (3, 0.16666667), (4, 0.16666667), (5, 0.16666667)]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = [['paris', 'holiday', 'condo']]\n",
    "tokenized_text = [['apoel', 'thrillos', 'afko']]\n",
    "\n",
    "\n",
    "vector = [lda_tfidf_model.id2word.doc2bow(text) for text in tokenized_text]\n",
    "topics = sorted(lda_tfidf_model.model[vector][0], key=lambda x: x[1], reverse=True)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
